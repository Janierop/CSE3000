{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymeshlab\n",
    "import numpy as np\n",
    "import typing\n",
    "from scipy.optimize import minimize\n",
    "from numba import jit, njit\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%config InlineBackend.figure_formats = ['svg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mesh(verts, faces, file_name):\n",
    "    saving_mesh = pymeshlab.Mesh(verts, faces)\n",
    "    saving_meshset = pymeshlab.MeshSet()\n",
    "    saving_meshset.add_mesh(saving_mesh)\n",
    "    saving_meshset.save_current_mesh(file_name, save_vertex_normal=False, save_vertex_color=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate bin structure\n",
    "we generate bins by tesalating a sphere to get the bin centers.\n",
    "We will use a fibbonacci sphere for this because it has some nice properties:\n",
    "- very evenly spaced spoints\n",
    "- arbitrary amount of points\n",
    "- simple algorithm\n",
    "- deterministic sequence of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def fibonacci_sphere(n):\n",
    "    goldenRatio = (1 + 5**0.5)/2\n",
    "    i = np.arange(0, n)\n",
    "    theta = 2 * np.pi * i / goldenRatio\n",
    "    phi = np.arccos(1 - 2*(i+0.5)/n)\n",
    "    x, y, z = np.cos(theta) * np.sin(phi), np.sin(theta) * np.sin(phi), np.cos(phi)\n",
    "\n",
    "    return np.column_stack((x,y,z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get radius of bins\n",
    "We get the radius (in radians) of bins by taking taking the smallest angle between two bin centers.  \n",
    "We get the smallest distance by brute force which means that with very large number of bins this becomes\n",
    "extremely computationally expensive.\n",
    "\n",
    "to get the angle theta between two vectors we use the fact that theta is equal to arccos(a dot b / (|a|*|b|))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_min_radius(verts):\n",
    "    min = np.finfo(np.float64).max\n",
    "    for i in range(len(verts)):\n",
    "        for j in range(len(verts)):\n",
    "            if (i != j): # dont compare a point to itself\n",
    "                a = verts[i]\n",
    "                b = verts[j]\n",
    "                # get angle distance\n",
    "                dist = np.arccos(a @ b)\n",
    "                if dist < min: min = dist # if this is the smallest so far then update\n",
    "    return min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating face normals\n",
    "Since we want to put all the face normals into their correct bins we first need to calculate each normal of each face.\n",
    "We do this by doing the cross product way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def normalize(vector):\n",
    "    cp = np.copy(vector)\n",
    "    return cp / np.linalg.norm(cp)\n",
    "@njit\n",
    "def get_face_normals(verts, faces):\n",
    "    tmp = np.zeros((len(faces), 3), dtype=np.float64)\n",
    "    #arr = [get_normal(verts, face) for face in faces]\n",
    "    for i, face in enumerate(faces):\n",
    "        tmp[i] = get_face_normal(verts, face)\n",
    "    return tmp\n",
    "    \n",
    "@njit\n",
    "def get_face_normal(verts, face):\n",
    "    # get vertices\n",
    "    p1 = verts[face[0]]\n",
    "    p2 = verts[face[1]]\n",
    "    p3 = verts[face[2]]\n",
    "\n",
    "    u = p2 - p1\n",
    "    v = p3 - p1\n",
    "\n",
    "    return np.cross(u, v)\n",
    "\n",
    "# calculate face normal but replace a vertex with a new value\n",
    "@njit\n",
    "def get_face_normal_with_vertex_substitution(verts, face, sub_vertex_index, sub_vertex_value):\n",
    "    # get vertices\n",
    "    p1 = verts[face[0]] if face[0] != sub_vertex_index else sub_vertex_value\n",
    "    p2 = verts[face[1]] if face[1] != sub_vertex_index else sub_vertex_value\n",
    "    p3 = verts[face[2]] if face[2] != sub_vertex_index else sub_vertex_value\n",
    "\n",
    "    u = p2 - p1\n",
    "    v = p3 - p1\n",
    "\n",
    "    return np.cross(u, v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting the face normals into their bins\n",
    "We will the face normals into their bins. To prevent that a normal can go into two bins we will find the smallest angle between two bins and half that.\n",
    "This angle will be the angle angle with the bincenter a face normal must be have to be put in that bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_face_normals(bin_centers, face_normals):\n",
    "    # normalize inputs\n",
    "    normed_bin_centers = np.copy(bin_centers)\n",
    "    for i, center in enumerate(normed_bin_centers):\n",
    "        normed_bin_centers[i] = center / np.linalg.norm(center)\n",
    "\n",
    "    normed_face_normals = np.copy(face_normals)\n",
    "    for i, face_normal in enumerate(normed_face_normals):\n",
    "        normed_face_normals[i] = face_normal / np.linalg.norm(face_normal)\n",
    "\n",
    "    # get the minimum distance between bin centers and half it\n",
    "    max_angle = get_min_radius(normed_bin_centers) / 2.0\n",
    "\n",
    "    # create bins. A list where each element is a list of the indices of the face normals that should go in there.\n",
    "    # note wierd syntax to instruct numba what the data type is by using \"for x in range(0)\"\n",
    "    bins = []\n",
    "    for i in normed_bin_centers:\n",
    "        bins.append([np.int64(x) for x in range(0)])\n",
    "\n",
    "    # for face normal check it it lies less than max_angle away from a bin and if it does put it in that bin.\n",
    "    for i, face_normal in enumerate(normed_face_normals):\n",
    "        for j, bin_center in enumerate(normed_bin_centers):\n",
    "            \n",
    "            angle = np.arccos(np.dot(face_normal, bin_center))\n",
    "            if (angle < max_angle): # if angle is smaller than max_angle then put i in bin j\n",
    "                bins[j].append(i)\n",
    "                break # since a normal can go in at most one bin we can break\n",
    "    \n",
    "    return bins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deriving coordinates in 2D\n",
    "After we have the face normals per bin we need to calculate each of their 2d position relative to the bin center.\n",
    "We do this by apply two rotations to the bin center, first around the x axis and then the y axis, to map the bin center to the z axis.\n",
    "\n",
    "We derive a sequence of to rotations: first by some angle theta around the x axis and second one by some angle gamma around the y axis that will move the bin center to the z axis. This transformation we will call T. By also applying T to the face normals we can effectively get their coordinates in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_transformation(bin_center):\n",
    "    x, y, z = bin_center # decompose the input vector\n",
    "    # find angle to rotate around x axis. opposite angle is y coordinate. adjescent angle is the z coordinate\n",
    "    theta = np.arctan2(y, z)\n",
    "\n",
    "    # find angle to rotate around y axis. opposite angle is the x coordinate. adjacent angle is (y**2 + z**2)**0.5\n",
    "    adjacent = np.sqrt(y**2 + z**2)\n",
    "    gamma = -np.arctan2(x, adjacent) # notice we have to negate the angle because we want to rotate against right hand rule\n",
    "\n",
    "    # to get the bin center to the z axis we apply first Rx(theta) then Ry(gamma). So the inverse is first Ry(-gamma) then Rx(-theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_gamma = np.sin(gamma)\n",
    "    cos_gamma = np.cos(gamma)\n",
    "   \n",
    "    rx = np.array(\n",
    "        [\n",
    "            [1.0, 0.0, 0.0],\n",
    "            [0.0, cos_theta, -sin_theta],\n",
    "            [0.0, sin_theta, cos_theta]\n",
    "        ], dtype=np.float64\n",
    "    )\n",
    "    ry = np.array(\n",
    "        [\n",
    "            [cos_gamma, 0.0, sin_gamma],\n",
    "            [0.0, 1.0, 0.0],\n",
    "            [-sin_gamma, 0.0, cos_gamma]\n",
    "        ], dtype=np.float64\n",
    "    )\n",
    "    \n",
    "    return ry @ rx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal adjacency list\n",
    "We need to be able to get the face normals of the faces adjacent to point p. For quick access we will create an adjacency list for each vertex in the model. A list of the indices of the faces adjacent to vertex will be found at adjacent_faces[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calculate_adjacent_faces_indices(vertices, faces):\n",
    "    # create the resulting list and populate it with empty lists that will eventually contain the indices of adjacent faces\n",
    "    res = []\n",
    "    for i in range(len(vertices)):\n",
    "        res.append([np.int64(x) for x in range(0)]) # some syntax tricks to indicate to numba what types should be inferred\n",
    "    \n",
    "    for index, face in enumerate(faces): # for each face\n",
    "        for vertex in face: # for each vertex in the face\n",
    "            # append the current face index to list adjacency list of the current vertex\n",
    "            res[vertex].append(index)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bin idx from face idx\n",
    "def calculate_face_to_bin_relation(bins, faces):\n",
    "    res = [-1 for x in range(len(faces))] # each face has in bin -1 initially meaning it not in a bin\n",
    "    # use our list of bins with their contained face normals to populate this result\n",
    "    for bin_idx, bin in enumerate(bins):\n",
    "        for face_idx in bin:\n",
    "            res[face_idx] = bin_idx\n",
    "    return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Optimization Step\n",
    "call hierarchy:  \n",
    "main()  \n",
    "    optimize_vertex()  \n",
    "    cost()  \n",
    "    multidimentional_downhill_simplex()  \n",
    "        costFunc()  \n",
    "        cost()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2D_coordinates(proj_matrix, vector3D):\n",
    "    epsilon = 0.01\n",
    "    projected_vector = proj_matrix @ vector3D\n",
    "    xp = projected_vector[0]\n",
    "    yp = projected_vector[1]\n",
    "    h = projected_vector[2]\n",
    "    l1 = np.arccos(h)\n",
    "    l2 = np.sqrt(xp**2.0 + yp**2.0)\n",
    "    x_ij = 0 if l2 < epsilon else xp * l1 / l2 \n",
    "    y_ij = 0 if l2 < epsilon else yp * l1 / l2 \n",
    "    return np.array([x_ij, y_ij])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bin center of masses\n",
    "def calculate_center_of_mass_2D(bins, normalized_normals, projection_matrices_3Dto2D):\n",
    "    center_of_mass = []\n",
    "    for bin_idx, bin in enumerate(bins):\n",
    "        com = np.array([0.0, 0.0])\n",
    "        count = 0\n",
    "        for normal_idx in bin:\n",
    "            normal = normalized_normals[normal_idx]\n",
    "            proj_matrix = projection_matrices_3Dto2D[bin_idx]\n",
    "            resulting_2D_coords = get_2D_coordinates(proj_matrix, normal)\n",
    "            com = com + resulting_2D_coords\n",
    "            count = count + 1\n",
    "        if count > 0:\n",
    "            center_of_mass.append(com / count)\n",
    "        else:\n",
    "            center_of_mass.append(com)\n",
    "    return center_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costs(new_normal_2d, original_normal_2d, bin_number, secret):\n",
    "    delta_max = 0.3 # maximum normal drift in the x direction\n",
    "    w1 = 0.4\n",
    "    w2 = 0.6\n",
    "    x_ij_new = new_normal_2d[0]\n",
    "    y_ij_new = new_normal_2d[1]\n",
    "    x_ij_old = original_normal_2d[0]\n",
    "    y_ij_old = original_normal_2d[1]\n",
    "    r_new = np.sqrt(x_ij_new**2.0 + y_ij_new**2.0)\n",
    "    r_old = np.sqrt(x_ij_old**2.0 + y_ij_old**2.0)\n",
    "    diff = x_ij_new - x_ij_old if secret[bin_number] == 0 else x_ij_old - x_ij_new\n",
    "    c1 = np.abs(r_new - r_old)\n",
    "    c2 = 2 if (np.abs(diff) > delta_max) else delta_max - diff if (0 <= diff) else 1\n",
    "    c = w1 * c1 + w2 * c2\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cost function to minimize. this is a wrapper for the costs(p) function with some guards\n",
    "def cost_func_builder(current_p_index, delta, secret, vertices, faces, bin_centers, face_normals, face_number_to_bin_number, bin_radius, projection_matrices, adjacent_faces):\n",
    "    def cost_func(new_p_value):\n",
    "        # max_costs = 0\n",
    "        costs_l = []\n",
    "        # if search space exceeded return 2, 2 is the max value for costs\n",
    "        if delta < 0:\n",
    "            return 2\n",
    "        \n",
    "        # a was 5 degrees which is 0.0872665 radians\n",
    "        a = 0.04 # 0.0872665\n",
    "\n",
    "        # b was 10 degrees which is 0.174533 radians\n",
    "        b = 0.174533\n",
    "\n",
    "        # for all triangle normals (TN) adjacent to p\n",
    "        for face_idx in adjacent_faces[current_p_index]:\n",
    "            face = faces[face_idx]\n",
    "            new_TN = normalize(get_face_normal_with_vertex_substitution(vertices, face, current_p_index, new_p_value)) # new normal calculated new p\n",
    "            original_TN = face_normals[face_idx]\n",
    "            original_bin_idx = face_number_to_bin_number[face_idx]\n",
    "\n",
    "            # calculate difference between the new normal as result of new vertex position and original normal\n",
    "            angle_diff = np.arccos(original_TN @ new_TN)\n",
    "\n",
    "            # if TN is not in a bin. This means that original bin is -1\n",
    "            if original_bin_idx == -1:\n",
    "                # if difference between actual TN and original TN > a return 2\n",
    "                if angle_diff > a:\n",
    "                    return 2.0\n",
    "\n",
    "            \n",
    "            # if TN has an original bin.\n",
    "            if original_bin_idx != -1:\n",
    "                # if difference between actual TN and original TN > b  return 2.0\n",
    "                if angle_diff > b:\n",
    "                    return 2.0\n",
    "            \n",
    "                # TN left its original bin return 2\n",
    "                if np.arccos(bin_centers[original_bin_idx] @ new_TN) > bin_radius:\n",
    "                    return 2.0\n",
    "\n",
    "                # if all the constraints pass then we can calculate the actual cost of the face normal\n",
    "                projection_matrix = projection_matrices[original_bin_idx]\n",
    "                new_normal_2d = get_2D_coordinates(projection_matrix, new_TN)\n",
    "                original_normal_2d = get_2D_coordinates(projection_matrix, original_TN)\n",
    "                c = costs(new_normal_2d, original_normal_2d, original_bin_idx, secret)\n",
    "\n",
    "                # if c > max_costs:\n",
    "                #     max_costs = c\n",
    "                costs_l.append(c)\n",
    "\n",
    "        return (sum(costs_l) / len(costs_l)) if (len(costs_l) > 0) else 0\n",
    "    return cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a cost function this will find return an improved position for the vertex p\n",
    "def multidimentional_downhill_simplex(p_index, delta, vertices, faces, bin_centers, face_normals, face_number_to_bin_number, bin_radius, projection_matrices, secret, adjacent_faces):\n",
    "    initial_vertex_position = vertices[p_index]\n",
    "    result = minimize(\n",
    "        cost_func_builder(p_index, delta, secret, vertices, faces, bin_centers, face_normals, face_number_to_bin_number, bin_radius, projection_matrices, adjacent_faces),\n",
    "        initial_vertex_position,\n",
    "        method='nelder-mead',\n",
    "        options={\"maxiter\": 30}\n",
    "        )\n",
    "    return result['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_vertex(vertex_number, delta, vertices, faces, bin_centers, face_normals, face_number_to_bin_number, bin_radius, projection_matrices, secret, adjacent_faces):\n",
    "    # initial_cost = costs(p)\n",
    "    p_new = multidimentional_downhill_simplex(vertex_number, delta, vertices, faces, bin_centers, face_normals, face_number_to_bin_number, bin_radius, projection_matrices, secret, adjacent_faces)\n",
    "    vertices[vertex_number] = p_new # update the vertex to the new coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_watermark(vertices, faces, secret):\n",
    "    delta = 20 # initial search range\n",
    "    iterations = 5 # number of iterations\n",
    "    refinements = 3 #number of refinements\n",
    "\n",
    "    # copy vertices so that we do not modify the original array\n",
    "    vertices_new = np.copy(vertices)\n",
    "    faces_new = np.copy(faces) \n",
    "\n",
    "\n",
    "    face_normals = [normalize(x) for x in get_face_normals(vertices_new, faces_new)] # face normal for face i can be found at face_normals[i]\n",
    "    bin_centers = fibonacci_sphere(len(secret)) # bin center for bin i can be found at bin_centers[i]\n",
    "    bins = collect_face_normals(bin_centers, face_normals) # the indices of the face normals in bin i are found in bins[i]\n",
    "    bin_angle_radius = get_min_radius(bin_centers) / 2.0\n",
    "    bin_projection_matrices = [get_transformation(bin_center) for bin_center in bin_centers] # to project a vector into the bases defined by bin i use bin_projection_matrices[i]\n",
    "    face_to_bin = calculate_face_to_bin_relation(bins, faces_new)\n",
    "    center_of_mass = calculate_center_of_mass_2D(bins, face_normals, bin_projection_matrices)\n",
    "    # adjacency list per vertex\n",
    "    adjacent_faces = calculate_adjacent_faces_indices(vertices_new, faces) # indices of adjacent faces to vertex i are found in adjacent_faces[i]\n",
    "\n",
    "\n",
    "    for i in range(iterations):\n",
    "        for vertex_number in tqdm(range(len(vertices_new))): #tqdm sets up a progress bar\n",
    "            for j in range(refinements):\n",
    "                optimize_vertex(\n",
    "                    vertex_number, \n",
    "                    delta, \n",
    "                    vertices_new, \n",
    "                    faces_new, \n",
    "                    bin_centers, \n",
    "                    face_normals, \n",
    "                    face_to_bin, \n",
    "                    bin_angle_radius, \n",
    "                    bin_projection_matrices,\n",
    "                    secret,\n",
    "                    adjacent_faces\n",
    "                )\n",
    "        # delta = delta - 1\n",
    "\n",
    "\n",
    "\n",
    "    face_normals_new = [normalize(x) for x in get_face_normals(vertices_new, faces_new)]\n",
    "    com_after = calculate_center_of_mass_2D(bins, face_normals_new, bin_projection_matrices)\n",
    "    mark = []\n",
    "    for i in range(len(center_of_mass)):\n",
    "        if center_of_mass[i][0] < com_after[i][0]:\n",
    "            mark.append(0)\n",
    "        else:\n",
    "            mark.append(1)\n",
    "\n",
    "    print(mark)\n",
    "    \n",
    "    # Return the vertices and faces of the watermarked mesh. We need to also return the original center of masses for each bin which is needed to retrieve the watermark\n",
    "    return vertices_new, faces_new, center_of_mass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_watermark(vertices, faces, original_centers_of_mass):\n",
    "    face_normals = [normalize(x) for x in get_face_normals(vertices, faces)] # face normal for face i can be found at face_normals[i]\n",
    "    bin_centers = fibonacci_sphere(len(original_centers_of_mass)) # bin center for bin i can be found at bin_centers[i]\n",
    "    bins = collect_face_normals(bin_centers, face_normals) # the indices of the face normals in bin i are found in bins[i]\n",
    "    bin_projection_matrices = [get_transformation(bin_center) for bin_center in bin_centers] # to project a vector into the bases defined by bin i use bin_projection_matrices[i]\n",
    "    new_centers_of_mass = calculate_center_of_mass_2D(bins, face_normals, bin_projection_matrices)\n",
    "\n",
    "    mark = []\n",
    "    for i in range(len(original_centers_of_mass)):\n",
    "        if original_centers_of_mass[i][0] < new_centers_of_mass[i][0]:\n",
    "            mark.append(0)\n",
    "        else:\n",
    "            mark.append(1)\n",
    "\n",
    "    retrieved_string = np.array(mark)\n",
    "\n",
    "    return retrieved_string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomization attack\n",
    "A simple randomization attack that moves every vertex a fixed distance a random direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_vertices_random(vertices, distance, seed):\n",
    "    n = len(vertices)\n",
    "    np.random.seed(seed)\n",
    "    displacements = [normalize(np.random.rand(3)) * distance for item in vertices]\n",
    "    res = np.copy(vertices)\n",
    "    for i in range(n):\n",
    "        res[i] = res[i] + displacements[i]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# determining if the retrieved watermark is correct\n",
    "The retrieved watermark is likely not a perfect match. Somebins have likely been flipped however most bins should not hav moved much.\n",
    "To determine if the retrieved bitstring is in corralated to the secret bitstring we first assume that the two are independant. Our\n",
    "Null Hypothesis is then that the retrieved bitstring is a random bitstring. If the chance of perceiving at least k matches between the two\n",
    "bitstrings is less than 1 percent we reject the null hypothesis and therefore believe that the secret did indeed watermark the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the probabilty of getting this result under the null hypothesis. If this probabilty is less than 1% reject the null hypothesis\n",
    "def calculate_match_probability(secret, retrieved_secret):\n",
    "    matches = np.array(secret) == np.array(retrieved_secret)\n",
    "    matching_count = sum(matches)\n",
    "    n = len(matches)\n",
    "    # calculate the probability that a random string matches the secret in more than matching_count positions\n",
    "    probability = sum([math.comb(n, k) for k in range(matching_count, n + 1)]) / 2**n\n",
    "    return probability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry stuff for presentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.248, 0.0, 0.969],\n",
       " [-0.312, -0.286, 0.906],\n",
       " [0.047, 0.535, 0.844],\n",
       " [0.38, -0.495, 0.781],\n",
       " [-0.685, 0.121, 0.719],\n",
       " [0.637, 0.405, 0.656],\n",
       " [-0.209, -0.777, 0.594],\n",
       " [-0.39, 0.752, 0.531],\n",
       " [0.83, -0.303, 0.469],\n",
       " [-0.845, -0.349, 0.406],\n",
       " [0.398, 0.851, 0.344],\n",
       " [0.287, -0.916, 0.281],\n",
       " [-0.844, 0.489, 0.219],\n",
       " [0.965, 0.212, 0.156],\n",
       " [-0.573, -0.814, 0.094],\n",
       " [-0.128, 0.991, 0.031],\n",
       " [0.764, -0.644, -0.031],\n",
       " [-0.995, -0.041, -0.094],\n",
       " [0.7, 0.697, -0.156],\n",
       " [-0.045, -0.975, -0.219],\n",
       " [-0.615, 0.737, -0.281],\n",
       " [0.931, -0.125, -0.344],\n",
       " [-0.75, -0.522, -0.406],\n",
       " [0.194, 0.862, -0.469],\n",
       " [0.421, -0.735, -0.531],\n",
       " [-0.767, 0.245, -0.594],\n",
       " [0.685, 0.316, -0.656],\n",
       " [-0.268, -0.641, -0.719],\n",
       " [-0.211, 0.587, -0.781],\n",
       " [0.475, -0.25, -0.844],\n",
       " [-0.409, -0.108, -0.906],\n",
       " [0.134, 0.209, -0.969]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get fibonacci sphere points\n",
    "fib_points = fibonacci_sphere(32)\n",
    "# get the bin radius for these bins\n",
    "bin_r = get_min_radius(fib_points)\n",
    "[[round(x[0], 3), round(x[1], 3), round(x[2], 3)] for x in fib_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mesh(fib_points, [], \"fib32.obj\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "The area beneath this is used to test and execute the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = pymeshlab.MeshSet()\n",
    "ms.load_new_mesh(\"bishop.obj\")\n",
    "mesh = ms.current_mesh()\n",
    "\n",
    "verts = mesh.vertex_matrix() # vertex i is found at verts[i]\n",
    "faces = mesh.face_matrix() # face i is found at faces[i] and is a numpy array containing 3 indices representing the 3 vertices\n",
    "\n",
    "secret = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "secret_length = len(secret)\n",
    "print(secret_length)\n",
    "# used just for debugging\n",
    "current_vertex_finger = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed watermark\n",
    "result_vertices, result_faces, original_centers_of_mass = embed_watermark(verts, faces, secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attacked_vertices = attack_vertices_random(result_vertices, 0.05, 3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mesh(result_vertices, result_faces, \"voxel0p1-watermarked.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_string = retrieve_watermark(attacked_vertices, result_faces, original_centers_of_mass)\n",
    "res = calculate_match_probability(secret, retrieved_string)\n",
    "print(res)\n",
    "retrieved_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for regularization of 0.1 voxel size and and 32 bit bitstring\n",
    "# no remeshing before extraction:\n",
    "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "r1 = 2.3283064365386963e-10\n",
    "# 0.000 noise.\n",
    "[0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "r2 = 0.025051229866221547\n",
    "# 0.001 noise.\n",
    "[0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "r3 = 0.025051229866221547\n",
    "# 0.002 noise.\n",
    "[0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "r4 = 0.025051229866221547\n",
    "# 0.004 noise.\n",
    "[0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "r4 = 0.025051229866221547\n",
    "# 0.008 noise.\n",
    "[0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
    "r5 = 0.025051229866221547\n",
    "# 0.016 noise. \n",
    "[0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]\n",
    "r6 = 0.025051229866221547\n",
    "# 0.032 noise.\n",
    "[0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]\n",
    "r7 = 0.055092082591727376\n",
    "# 0.064 noise.\n",
    "[0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n",
    "r8 = 0.18854279373772442\n",
    "#0.128 noise\n",
    "[0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n",
    "r9 = 0.29830744792707264\n",
    "#0.256 noise\n",
    "[0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0]\n",
    "r10 = 0.4300250329542905\n",
    "\n",
    "noises = [0, 0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256]\n",
    "props = [r1, r2, r3, r4, r5, r6, r7, r8, r9, r10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(noises, props)\n",
    "plt.xlabel(\"vertex displacement distance\")\n",
    "plt.ylabel(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomization_experiment(vertices, faces, secret, centers_of_mass):\n",
    "    attack_distances = np.linspace(0, 0.5, 20)\n",
    "    runs = 50 # how many times the experiment is run for the same distance. should average over these runs\n",
    "    seed = 5432\n",
    "    averaged_scores = []\n",
    "    for dist in tqdm(attack_distances):\n",
    "        scores = []\n",
    "        for run in range(runs):\n",
    "            attacked_vertices = attack_vertices_random(vertices, dist, seed) # randomization attack\n",
    "            seed = seed + 1 # change seed for next attack\n",
    "            extracted_secret = retrieve_watermark(attacked_vertices, faces, centers_of_mass)\n",
    "            score = calculate_match_probability(secret, extracted_secret)\n",
    "            scores.append(score)\n",
    "\n",
    "        # add the average of the scores to the list\n",
    "        averaged_scores.append(sum(scores) / len(scores))\n",
    "    return (attack_distances, averaged_scores)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_verts, embedded_faces, centers_of_mass_og = embed_watermark(verts, faces, secret) # first embed the watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using no regularization what so ever\n",
    "distances_og, scores_og = randomization_experiment(embedded_verts, embedded_faces, secret, centers_of_mass_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, scores = randomization_experiment(result_vertices, result_faces, secret, original_centers_of_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distances, scores, label=\"regularization before embedding\")\n",
    "plt.plot(noises, props, label=\"with regularization\")\n",
    "plt.plot(distances_og, scores_og, label=\"no regularization\")\n",
    "plt.xlabel(\"vertex displacement distance\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secret_length_experiment(vertices, faces):\n",
    "    xs = list(range(64, 128, 8)) # the length of the secret\n",
    "    runs = 5 # how many times the experiment is run for the same distance. should average over these runs\n",
    "    seed = 5432\n",
    "    attack_distance = 0.01\n",
    "    ys = []\n",
    "    for key_length in tqdm(xs):\n",
    "        scores = []\n",
    "        for run in range(runs):\n",
    "            key = np.ones(int(key_length))\n",
    "            marked_verts, marked_faces, centers_of_mass = embed_watermark(vertices, faces, key) # first embed the watermark\n",
    "\n",
    "            attacked_vertices = attack_vertices_random(marked_verts, attack_distance, seed) # randomization attack\n",
    "            seed = seed + 1 # change seed for next attack\n",
    "            extracted_secret = retrieve_watermark(attacked_vertices, faces, centers_of_mass)\n",
    "            score = calculate_match_probability(key, extracted_secret)\n",
    "            scores.append(score)\n",
    "\n",
    "        # add the average of the scores to the list\n",
    "        ys.append(sum(scores) / len(scores))\n",
    "    return (xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = secret_length_experiment(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## key length experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack distance was 0.01 and all the attacks had different seed. each score is the average over 5 runs\n",
    "varying_key_lengths2 = [64, 72, 80, 88, 96, 104, 112, 120]\n",
    "varying_key_length_scores2 = [\n",
    "    2.4613128152370216e-05,\n",
    "    1.3753310269125764e-06,\n",
    "    1.8589254322534538e-07,\n",
    "    5.321711702864933e-06,\n",
    "    2.9494822301267367e-05,\n",
    "    1.4337786063673886e-05,\n",
    "    1.9933532240097227e-05,\n",
    "    3.19929274643322e-09]\n",
    "\n",
    "# attack distance was 0.01 and all the attacks had different seed. each score is the average over 5 runs\n",
    "varying_key_lengths = [\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "    11,\n",
    "    12,\n",
    "    13,\n",
    "    14,\n",
    "    15,\n",
    "    16,\n",
    "    17,\n",
    "    18,\n",
    "    19,\n",
    "    20,\n",
    "    21,\n",
    "    22,\n",
    "    23,\n",
    "    24,\n",
    "    25,\n",
    "    26,\n",
    "    27,\n",
    "    28,\n",
    "    29,\n",
    "    30,\n",
    "    31,\n",
    "    32,\n",
    "    33,\n",
    "    34,\n",
    "    35,\n",
    "    36,\n",
    "    37,\n",
    "    38,\n",
    "    39,\n",
    "    40,\n",
    "    41,\n",
    "    42,\n",
    "    43,\n",
    "    44,\n",
    "    45,\n",
    "    46,\n",
    "    47,\n",
    "    48,\n",
    "    49,\n",
    "    50,\n",
    "    51,\n",
    "    52,\n",
    "    53,\n",
    "    54,\n",
    "    55,\n",
    "    56,\n",
    "    57,\n",
    "    58,\n",
    "    59,\n",
    "    60,\n",
    "    61,\n",
    "    62,\n",
    "    63]\n",
    "varying_key_length_scores = [\n",
    "    0.03125,\n",
    "    0.053125,\n",
    "    0.0078125,\n",
    "    0.00390625,\n",
    "    0.001953125,\n",
    "    0.0009765625,\n",
    "    0.00048828125,\n",
    "    0.000244140625,\n",
    "    0.001708984375,\n",
    "    0.00185546875,\n",
    "    0.002410888671875,\n",
    "    0.0001129150390625,\n",
    "    7.62939453125e-06,\n",
    "    3.814697265625e-06,\n",
    "    9.1552734375e-06,\n",
    "    0.0005197525024414062,\n",
    "    0.00023746490478515625,\n",
    "    0.0005221366882324219,\n",
    "    2.312660217285156e-06,\n",
    "    3.219842910766602e-05,\n",
    "    3.534555435180664e-05,\n",
    "    1.6987323760986329e-07,\n",
    "    5.707144737243652e-07,\n",
    "    6.3978135585784915e-06,\n",
    "    5.79833984375e-05,\n",
    "    1.043081283569336e-07,\n",
    "    6.886199116706848e-06,\n",
    "    2.2596213966608047e-06,\n",
    "    3.431783989071846e-06,\n",
    "    7.705064490437508e-07,\n",
    "    1.7075217328965664e-07,\n",
    "    2.865272108465433e-08,\n",
    "    1.341817551292479e-07,\n",
    "    5.597226845566183e-07,\n",
    "    1.0448784451000393e-07,\n",
    "    1.0138066500076092e-06,\n",
    "    2.465534635121003e-07,\n",
    "    2.293745637871325e-09,\n",
    "    3.1317085813498124e-09,\n",
    "    5.7911643125407865e-08,\n",
    "    5.621776608677465e-08,\n",
    "    1.9252243816936242e-07,\n",
    "    2.5285731325652706e-06,\n",
    "    2.1946914834813926e-06,\n",
    "    1.555259969947542e-05,\n",
    "    5.711858488410826e-07,\n",
    "    1.6159703264406744e-07,\n",
    "    1.3553069635463544e-06,\n",
    "    4.158851707458666e-09,\n",
    "    1.8859686095051842e-06,\n",
    "    5.5357716799431245e-08,\n",
    "    1.85352950626827e-07,\n",
    "    4.2466138305136125e-07,\n",
    "    1.0776873615725435e-08,\n",
    "    2.589912086181645e-07,\n",
    "    1.3982240510759802e-06,\n",
    "    2.9813126864611758e-06,\n",
    "    7.251385393341548e-06,\n",
    "    7.612654095823278e-06]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((varying_key_lengths + varying_key_lengths2),( varying_key_length_scores + varying_key_length_scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a12d51c86ae5a9e0728790e9f226ac055370ed14b27e8d69cccd17f51d83081"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
